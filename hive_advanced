A. Create table and load as text file
-------------------------------------
1.
DROP TABLE twittble;

CREATE TABLE twittble(tweetId BIGINT, username STRING,txt STRING, CreatedAt STRING,     profileLocation STRING,favc BIGINT,retweet STRING,retcount BIGINT,followerscount BIGINT)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t'
STORED AS TEXTFILE;

2.    
LOAD  DATA LOCAL INPATH  '/home/dbtrain/<<urname>>/TwitterData.txt' OVERWRITE INTO TABLE twittble;

3.
SELECT * FROM twittble;
! hadoop fs -ls /user/hive/warehouse/twittble;



B. Create table and load as ORC file
-------------------------------------
Optimized Row Columnar (ORC) File format is used as it further compresses data files. It could result in a small performance loss in writing, but there will be huge performance gain in reading.

1.
DROP TABLE twitorctbl;

CREATE TABLE twitorctbl(tweetId BIGINT, username STRING,txt STRING, CreatedAt STRING, profileLocation STRING COMMENT 'Location of user',favc INT,retweet STRING,retcount INT,followerscount INT)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY 't'
STORED AS ORC tblproperties ("orc.compress"="NONE");

2.
INSERT INTO TABLE twitorctbl SELECT * FROM twittble;

3.
SELECT * FROM twitorctbl;
! hadoop fs -ls /user/hive/warehouse/twitorctbl;
! hadoop fs -tail /user/hive/warehouse/twitorctbl/000000_0;


